{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49471f3d-bbee-4181-9aca-dfc56afa2bf6",
   "metadata": {},
   "source": [
    "## Anomaly Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ba4642b-87b4-4ef3-a0d2-8fe095197a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix,coo_matrix\n",
    "from sklearn.cluster import SpectralClustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28f3fed7-e775-456c-9a41-8f598a701bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def anomaly_generation(ini_graph_percent, anomaly_percent, data, n, m, seed = 1):\n",
    "    np.random.seed(seed)\n",
    "    print('[#s] generating anomalous dataset...\\n', datetime.datetime.now())\n",
    "    print('[#s] initial network edge percent: #.1f##, anomaly percent: #.1f##.\\n', datetime.datetime.now(),\n",
    "          ini_graph_percent * 100, anomaly_percent * 100)\n",
    "\n",
    "    # ini_graph_percent = 0.5;\n",
    "    # anomaly_percent = 0.05;\n",
    "    train_num = int(np.floor(ini_graph_percent * m))\n",
    "\n",
    "    # select part of edges as in the training set\n",
    "    train = data[0:train_num, :]\n",
    "\n",
    "    # select the other edges as the testing set\n",
    "    test = data[train_num:, :]\n",
    "\n",
    "    #data to adjacency_matrix\n",
    "    adjacency_matrix = edgeList2Adj(data)\n",
    "\n",
    "    # clustering nodes to clusters using spectral clustering\n",
    "    kk = 42 #3#10#42#42\n",
    "    sc = SpectralClustering(kk, affinity='precomputed', n_init=10, assign_labels = 'discretize',n_jobs=-1)\n",
    "    labels = sc.fit_predict(adjacency_matrix)\n",
    "\n",
    "\n",
    "    # generate fake edges that are not exist in the whole graph, treat them as\n",
    "    # anamalies\n",
    "    idx_1 = np.expand_dims(np.transpose(np.random.choice(n, m)), axis=1)\n",
    "    idx_2 = np.expand_dims(np.transpose(np.random.choice(n, m)), axis=1)\n",
    "    generate_edges = np.concatenate((idx_1, idx_2), axis=1)\n",
    "\n",
    "    ####### genertate abnormal edges ####\n",
    "    fake_edges = np.array([x for x in generate_edges if labels[x[0] - 1] != labels[x[1] - 1]])\n",
    "\n",
    "    fake_edges = processEdges(fake_edges, data)\n",
    "\n",
    "\n",
    "    #anomaly_num = 12#int(np.floor(anomaly_percent * np.size(test, 0)))\n",
    "    anomaly_num = int(np.floor(anomaly_percent * np.size(test, 0)))\n",
    "    anomalies = fake_edges[0:anomaly_num, :]\n",
    "\n",
    "    idx_test = np.zeros([np.size(test, 0) + anomaly_num, 1], dtype=np.int32)\n",
    "    # randsample: sample without replacement\n",
    "    # it's different from datasample!\n",
    "\n",
    "    anomaly_pos = np.random.choice(np.size(idx_test, 0), anomaly_num, replace=False)\n",
    "\n",
    "    #anomaly_pos = np.random.choice(100, anomaly_num, replace=False)+200\n",
    "\n",
    "    idx_test[anomaly_pos] = 1\n",
    "    synthetic_test = np.concatenate((np.zeros([np.size(idx_test, 0), 2], dtype=np.int32), idx_test), axis=1)\n",
    "\n",
    "    idx_anomalies = np.nonzero(idx_test.squeeze() == 1)\n",
    "    idx_normal = np.nonzero(idx_test.squeeze() == 0)\n",
    "\n",
    "    synthetic_test[idx_anomalies, 0:2] = anomalies\n",
    "    synthetic_test[idx_normal, 0:2] = test\n",
    "\n",
    "    train_mat = csr_matrix((np.ones([np.size(train, 0)], dtype=np.int32), (train[:, 0], train[:, 1])),\n",
    "                           shape=(n, n))\n",
    "    # sparse(train(:,1), train(:,2), ones(length(train), 1), n, n) #TODO: node addition\n",
    "    train_mat = train_mat + train_mat.transpose()\n",
    "\n",
    "    return synthetic_test, train_mat, train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a52939b-43b9-4ae3-a6b5-16379913437a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def anomaly_generation2(ini_graph_percent, anomaly_percent, data, n, m,seed = 1):\n",
    "    \"\"\" generate anomaly\n",
    "    split the whole graph into training network which includes parts of the\n",
    "    whole graph edges(with ini_graph_percent) and testing edges that includes\n",
    "    a ratio of manually injected anomaly edges, here anomaly edges mean that\n",
    "    they are not shown in previous graph;\n",
    "     input: ini_graph_percent: percentage of edges in the whole graph will be\n",
    "                                sampled in the intitial graph for embedding\n",
    "                                learning\n",
    "            anomaly_percent: percentage of edges in testing edges pool to be\n",
    "                              manually injected anomaly edges(previous not\n",
    "                              shown in the whole graph)\n",
    "            data: whole graph matrix in sparse form, each row (nodeID,\n",
    "                  nodeID) is one edge of the graph\n",
    "            n:  number of total nodes of the whole graph\n",
    "            m:  number of edges in the whole graph\n",
    "     output: synthetic_test: the testing edges with injected abnormal edges,\n",
    "                             each row is one edge (nodeID, nodeID, label),\n",
    "                             label==0 means the edge is normal one, label ==1\n",
    "                             means the edge is abnormal;\n",
    "             train_mat: the training network with square matrix format, the training\n",
    "                        network edges for initial model training;\n",
    "             train:  the sparse format of the training network, each row\n",
    "                        (nodeID, nodeID)\n",
    "    \"\"\"\n",
    "    # The actual generation method used for Netwalk(shown in matlab version)\n",
    "    # Abort the SpectralClustering\n",
    "    np.random.seed(seed)\n",
    "    print('[%s] generating anomalous dataset...\\n'% datetime.datetime.now())\n",
    "    print('[%s] initial network edge percent: %.2f, anomaly percent: %.2f.\\n'%(datetime.datetime.now(),\n",
    "          ini_graph_percent , anomaly_percent ))\n",
    "\n",
    "    # ini_graph_percent = 0.5;\n",
    "    # anomaly_percent = 0.05;\n",
    "    train_num = int(np.floor(ini_graph_percent * m))\n",
    "\n",
    "    # select part of edges as in the training set\n",
    "    train = data[0:train_num, :]\n",
    "\n",
    "    # select the other edges as the testing set\n",
    "    test = data[train_num:, :]\n",
    "\n",
    "    #data to adjacency_matrix\n",
    "    #adjacency_matrix = edgeList2Adj(data)\n",
    "\n",
    "    # clustering nodes to clusters using spectral clustering\n",
    "    # kk = 3 #3#10#42#42\n",
    "    # sc = SpectralClustering(kk, affinity='precomputed', n_init=10, assign_labels = 'discretize',n_jobs=-1)\n",
    "    # labels = sc.fit_predict(adjacency_matrix)\n",
    "\n",
    "\n",
    "    # generate fake edges that are not exist in the whole graph, treat them as\n",
    "    # anamalies\n",
    "   \n",
    "    idx_1 = np.expand_dims(np.transpose(np.random.choice(n, m)) , axis=1)\n",
    "    idx_2 = np.expand_dims(np.transpose(np.random.choice(n, m)) , axis=1)\n",
    "    fake_edges = np.concatenate((idx_1, idx_2), axis=1)\n",
    "\n",
    "    ####### genertate abnormal edges ####\n",
    "    #fake_edges = np.array([x for x in generate_edges if labels[x[0] - 1] != labels[x[1] - 1]])\n",
    "\n",
    "\n",
    "    fake_edges = processEdges(fake_edges, data)\n",
    "\n",
    "    #anomaly_num = 12#int(np.floor(anomaly_percent * np.size(test, 0)))\n",
    "  \n",
    "    anomaly_num = int(np.floor(anomaly_percent * np.size(test, 0)))\n",
    "    anomalies = fake_edges[0:anomaly_num, :]\n",
    "\n",
    "    idx_test = np.zeros([np.size(test, 0) + anomaly_num, 1], dtype=np.int32)\n",
    "    # randsample: sample without replacement\n",
    "    # it's different from datasample!\n",
    "\n",
    " \n",
    "    anomaly_pos = np.random.choice(np.size(idx_test, 0), anomaly_num, replace=False)\n",
    "\n",
    "    #anomaly_pos = np.random.choice(100, anomaly_num, replace=False)+200\n",
    "  \n",
    "    idx_test[anomaly_pos] = 1\n",
    "\n",
    "    synthetic_test = np.concatenate((np.zeros([np.size(idx_test, 0), 2], dtype=np.int32), idx_test), axis=1)\n",
    "    idx_anomalies = np.nonzero(idx_test.squeeze() == 1)\n",
    "    idx_normal = np.nonzero(idx_test.squeeze() == 0)\n",
    "    synthetic_test[idx_anomalies, 0:2] = anomalies\n",
    "    synthetic_test[idx_normal, 0:2] = test\n",
    "\n",
    "    # coo:efficient for matrix construction ;  csr: efficient for arithmetic operations\n",
    "    # coo+to_csr is faster for small matrix, but nearly the same for large matrix (size: over 100M)\n",
    "    #train_mat = csr_matrix((np.ones([np.size(train, 0)], dtype=np.int32), (train[:, 0] , train[:, 1])),shape=(n, n))\n",
    "    train_mat = coo_matrix((np.ones([np.size(train, 0)], dtype=np.int32), (train[:, 0], train[:, 1])), shape=(n, n)).tocsr()\n",
    "    # sparse(train(:,1), train(:,2), ones(length(train), 1), n, n)\n",
    "    train_mat = train_mat + train_mat.transpose()\n",
    "\n",
    "    return synthetic_test, train_mat, train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c75a0da5-d883-4cbd-8222-534042c6642c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def processEdges(fake_edges, data):\n",
    "    \"\"\"\n",
    "    remove self-loops and duplicates and order edge\n",
    "    :param fake_edges: generated edge list\n",
    "    :param data: orginal edge list\n",
    "    :return: list of edges\n",
    "    \"\"\"\n",
    "    # b:list->set\n",
    "    # Time cost rate is proportional to the size\n",
    "\n",
    "    idx_fake = np.nonzero(fake_edges[:, 0] - fake_edges[:, 1] > 0)\n",
    "\n",
    "    tmp = fake_edges[idx_fake]\n",
    "    tmp[:, [0, 1]] = tmp[:, [1, 0]]\n",
    "\n",
    "    fake_edges[idx_fake] = tmp\n",
    "\n",
    "    idx_remove_dups = np.nonzero(fake_edges[:, 0] - fake_edges[:, 1] < 0)\n",
    "\n",
    "    fake_edges = fake_edges[idx_remove_dups]\n",
    "    a = fake_edges.tolist()\n",
    "    b = data.tolist()\n",
    "    c = []\n",
    "\n",
    "    for i in a:\n",
    "        if i not in b:\n",
    "            c.append(i)\n",
    "    fake_edges = np.array(c)\n",
    "    return fake_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c50fce6-6ebe-4dcb-ae4f-43876544aa2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def edgeList2Adj(data):\n",
    "    \"\"\"\n",
    "    converting edge list to graph adjacency matrix\n",
    "    :param data: edge list\n",
    "    :return: adjacency matrix which is symmetric\n",
    "    \"\"\"\n",
    "\n",
    "    data = tuple(map(tuple, data))\n",
    "\n",
    "    n = max(max(user, item) for user, item in data)  # Get size of matrix\n",
    "    matrix = np.zeros((n, n))\n",
    "    for user, item in data:\n",
    "        matrix[user - 1][item - 1] = 1  # Convert to 0-based index.\n",
    "        matrix[item - 1][user - 1] = 1  # Convert to 0-based index.\n",
    "    return matrix\n",
    "\n",
    "#if __name__ == \"__main__\":\n",
    "    #data_path = \"data/karate.edges\"\n",
    "    # data_path = './fb-messages2.txt'\n",
    "\n",
    "    #edges = np.loadtxt(data_path, dtype=float, comments='%',delimiter=',')\n",
    "    #edges = edges[:,0:2].astype(dtype=int)\n",
    "\n",
    "    #vertices = np.unique(edges)\n",
    "    #m = len(edges)\n",
    "    #n = len(vertices)\n",
    "\n",
    "    #synthetic_test, train_mat, train = anomaly_generation(0.5, 0.1, edges, n, m)\n",
    "\n",
    "    #print(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0691a1a5-5e39-49a8-a889-77e8377ae9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import warnings\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Optional, Tuple, Union\n",
    "import time\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from scipy import sparse\n",
    "import scipy.sparse as sp\n",
    "from numpy.linalg import inv\n",
    "import torch\n",
    "import torch.utils.checkpoint\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.nn import BCEWithLogitsLoss, CrossEntropyLoss, MSELoss\n",
    "from transformers.models.bert.modeling_bert import BertAttention, BertIntermediate, BertOutput, BertPreTrainedModel, BertPooler\n",
    "from transformers.configuration_utils import PretrainedConfig\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f08a1b-d411-4523-ac05-f5ff5655f786",
   "metadata": {},
   "source": [
    "## Transformer Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "609eedcf-24aa-43a0-87be-19dec3100991",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEncoder(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(TransformerEncoder, self).__init__()\n",
    "        self.output_attentions = config.output_attentions\n",
    "        self.output_hidden_states = config.output_hidden_states\n",
    "        self.layer = nn.ModuleList([TransformerLayer(config) for _ in range(config.num_hidden_layers)])\n",
    "\n",
    "    def forward(self, hidden_states, attention_mask=None, head_mask=None, encoder_hidden_states=None, encoder_attention_mask=None):\n",
    "        all_hidden_states = ()\n",
    "        all_attentions = ()\n",
    "        for i, layer_module in enumerate(self.layer):\n",
    "            if self.output_hidden_states:\n",
    "                all_hidden_states = all_hidden_states + (hidden_states,)\n",
    "\n",
    "            layer_outputs = layer_module(hidden_states, attention_mask, head_mask[i], encoder_hidden_states, encoder_attention_mask)\n",
    "            hidden_states = layer_outputs[0]\n",
    "\n",
    "            if self.output_attentions:\n",
    "                all_attentions = all_attentions + (layer_outputs[1],)\n",
    "\n",
    "        # Add last layer\n",
    "        if self.output_hidden_states:\n",
    "            all_hidden_states = all_hidden_states + (hidden_states,)\n",
    "\n",
    "        outputs = (hidden_states,)\n",
    "        if self.output_hidden_states:\n",
    "            outputs = outputs + (all_hidden_states,)\n",
    "        if self.output_attentions:\n",
    "            outputs = outputs + (all_attentions,)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94477190-a546-4aef-88ca-426e9c58e2ea",
   "metadata": {},
   "source": [
    "## Edge Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "606fb833-2e1a-4843-b343-98823f38b191",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EdgeEncoding(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(EdgeEncoding, self).__init__()\n",
    "        self.config = config\n",
    "\n",
    "        self.inti_pos_embeddings = nn.Embedding(config.max_inti_pos_index, config.hidden_size)\n",
    "        self.hop_dis_embeddings = nn.Embedding(config.max_hop_dis_index, config.hidden_size)\n",
    "        self.time_dis_embeddings = nn.Embedding(config.max_hop_dis_index, config.hidden_size)\n",
    "\n",
    "        self.LayerNorm = TransformerLayerNorm(config.hidden_size, eps=config.layer_norm_eps)\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "\n",
    "    def forward(self, init_pos_ids=None, hop_dis_ids=None, time_dis_ids=None):\n",
    "\n",
    "        position_embeddings = self.inti_pos_embeddings(init_pos_ids)\n",
    "        hop_embeddings = self.hop_dis_embeddings(hop_dis_ids)\n",
    "        time_embeddings = self.hop_dis_embeddings(time_dis_ids)\n",
    "\n",
    "        embeddings = position_embeddings + hop_embeddings + time_embeddings\n",
    "        embeddings = self.LayerNorm(embeddings)\n",
    "        embeddings = self.dropout(embeddings)\n",
    "        return embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd94d6d-ed7b-485b-930f-fb79f5f9faac",
   "metadata": {},
   "source": [
    "## Transformer layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0104a525-17fe-4f14-87f6-2e5ea6781f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerLayer(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.attention = BertAttention(config)\n",
    "        self.is_decoder = config.is_decoder\n",
    "        if self.is_decoder:\n",
    "            self.crossattention = BertAttention(config)\n",
    "        self.intermediate = BertIntermediate(config)\n",
    "        self.output = BertOutput(config)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        hidden_states,\n",
    "        attention_mask=None,\n",
    "        head_mask=None,\n",
    "        encoder_hidden_states=None,\n",
    "        encoder_attention_mask=None,\n",
    "    ):\n",
    "        self_attention_outputs = self.attention(hidden_states, attention_mask, head_mask)\n",
    "        attention_output = self_attention_outputs[0]\n",
    "        outputs = self_attention_outputs[1:]\n",
    "\n",
    "        if self.is_decoder and encoder_hidden_states is not None:\n",
    "            cross_attention_outputs = self.crossattention(\n",
    "                attention_output, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask\n",
    "            )\n",
    "            attention_output = cross_attention_outputs[0]\n",
    "            outputs = outputs + cross_attention_outputs[1:]\n",
    "\n",
    "        intermediate_output = self.intermediate(attention_output)\n",
    "        layer_output = self.output(intermediate_output, attention_output)\n",
    "        outputs = (layer_output,) + outputs\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53b3a7f-6095-4e7b-8ed1-fffd5b035a92",
   "metadata": {},
   "source": [
    "## Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d36ec7d-f135-4ff6-bf48-55722e0e1dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseModel(BertPreTrainedModel):\n",
    "    data = None\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super(BaseModel, self).__init__(config)\n",
    "        self.config = config\n",
    "\n",
    "        self.embeddings = EdgeEncoding(config)\n",
    "        self.encoder = TransformerEncoder(config)\n",
    "        self.pooler = BertPooler(config)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def get_input_embeddings(self):\n",
    "        return self.embeddings.raw_feature_embeddings\n",
    "\n",
    "    def set_input_embeddings(self, value):\n",
    "        self.embeddings.raw_feature_embeddings = value\n",
    "\n",
    "    def _prune_heads(self, heads_to_prune):\n",
    "        for layer, heads in heads_to_prune.items():\n",
    "            self.encoder.layer[layer].attention.prune_heads(heads)\n",
    "\n",
    "    def setting_preparation(self, input_ids=None, attention_mask=None, token_type_ids=None, position_ids=None, head_mask=None, inputs_embeds=None, encoder_hidden_states=None, encoder_attention_mask=None,):\n",
    "\n",
    "        if input_ids is not None and inputs_embeds is not None:\n",
    "            raise ValueError(\"You cannot specify both input_ids and inputs_embeds at the same time\")\n",
    "        elif input_ids is not None:\n",
    "            input_shape = input_ids.size()\n",
    "        elif inputs_embeds is not None:\n",
    "            input_shape = inputs_embeds.size()[:-1]\n",
    "        else:\n",
    "            raise ValueError(\"You have to specify either input_ids or inputs_embeds\")\n",
    "\n",
    "        device = input_ids.device if input_ids is not None else inputs_embeds.device\n",
    "\n",
    "        if attention_mask is None:\n",
    "            attention_mask = torch.ones(input_shape, device=device)\n",
    "        if token_type_ids is None:\n",
    "            token_type_ids = torch.zeros(input_shape, dtype=torch.long, device=device)\n",
    "\n",
    "        if attention_mask.dim() == 3:\n",
    "            extended_attention_mask = attention_mask[:, None, :, :]\n",
    "        elif attention_mask.dim() == 2:\n",
    "            if self.config.is_decoder:\n",
    "                batch_size, seq_length = input_shape\n",
    "                seq_ids = torch.arange(seq_length, device=device)\n",
    "                causal_mask = seq_ids[None, None, :].repeat(batch_size, seq_length, 1) <= seq_ids[None, :, None]\n",
    "                causal_mask = causal_mask.to(torch.long)  # not converting to long will cause errors with pytorch version < 1.3\n",
    "                extended_attention_mask = causal_mask[:, None, :, :] * attention_mask[:, None, None, :]\n",
    "            else:\n",
    "                extended_attention_mask = attention_mask[:, None, None, :]\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                \"Wrong shape for input_ids (shape {}) or attention_mask (shape {})\".format(\n",
    "                    input_shape, attention_mask.shape\n",
    "                )\n",
    "            )\n",
    "\n",
    "        extended_attention_mask = extended_attention_mask.to(dtype=next(self.parameters()).dtype)  # fp16 compatibility\n",
    "        extended_attention_mask = (1.0 - extended_attention_mask) * -10000.0\n",
    "\n",
    "        if self.config.is_decoder and encoder_hidden_states is not None:\n",
    "            encoder_batch_size, encoder_sequence_length, _ = encoder_hidden_states.size()\n",
    "            encoder_hidden_shape = (encoder_batch_size, encoder_sequence_length)\n",
    "            if encoder_attention_mask is None:\n",
    "                encoder_attention_mask = torch.ones(encoder_hidden_shape, device=device)\n",
    "\n",
    "            if encoder_attention_mask.dim() == 3:\n",
    "                encoder_extended_attention_mask = encoder_attention_mask[:, None, :, :]\n",
    "            elif encoder_attention_mask.dim() == 2:\n",
    "                encoder_extended_attention_mask = encoder_attention_mask[:, None, None, :]\n",
    "            else:\n",
    "                raise ValueError(\n",
    "                    \"Wrong shape for encoder_hidden_shape (shape {}) or encoder_attention_mask (shape {})\".format(\n",
    "                        encoder_hidden_shape, encoder_attention_mask.shape\n",
    "                    )\n",
    "                )\n",
    "\n",
    "            encoder_extended_attention_mask = encoder_extended_attention_mask.to(dtype=next(self.parameters()).dtype)  # fp16 compatibility\n",
    "            encoder_extended_attention_mask = (1.0 - encoder_extended_attention_mask) * -10000.0\n",
    "        else:\n",
    "            encoder_extended_attention_mask = None\n",
    "\n",
    "        if head_mask is not None:\n",
    "            if head_mask.dim() == 1:\n",
    "                head_mask = head_mask.unsqueeze(0).unsqueeze(0).unsqueeze(-1).unsqueeze(-1)\n",
    "                head_mask = head_mask.expand(self.config.num_hidden_layers, -1, -1, -1, -1)\n",
    "            elif head_mask.dim() == 2:\n",
    "                head_mask = (\n",
    "                    head_mask.unsqueeze(1).unsqueeze(-1).unsqueeze(-1)\n",
    "                )  # We can specify head_mask for each layer\n",
    "            head_mask = head_mask.to(dtype=next(self.parameters()).dtype)\n",
    "        else:\n",
    "            head_mask = [None] * self.config.num_hidden_layers\n",
    "\n",
    "        return token_type_ids, extended_attention_mask, encoder_extended_attention_mask, head_mask\n",
    "\n",
    "\n",
    "    def forward(self, init_pos_ids, hop_dis_ids, time_dis_ids, head_mask=None):\n",
    "        if head_mask is None:\n",
    "            head_mask = [None] * self.config.num_hidden_layers\n",
    "\n",
    "        embedding_output = self.embeddings(init_pos_ids=init_pos_ids,\n",
    "                                           hop_dis_ids=hop_dis_ids, time_dis_ids=time_dis_ids)\n",
    "        encoder_outputs = self.encoder(embedding_output, head_mask=head_mask) #这里的输出是tuple，因为在某些设定下要输出别的信息（中间分析用）\n",
    "        sequence_output = encoder_outputs[0]\n",
    "        pooled_output = self.pooler(sequence_output)\n",
    "        outputs = (sequence_output, pooled_output,) + encoder_outputs[1:]\n",
    "        return outputs\n",
    "\n",
    "    def run(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59927f5-057c-4817-8185-e570b72cee06",
   "metadata": {},
   "source": [
    "## To Embedings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "772612eb-2ebb-453a-946f-64382820185c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dict to embeddings\n",
    "def dicts_to_embeddings(feats, batch_hop_dicts, wl_dict, num_snap, use_raw_feat=False):\n",
    "\n",
    "    raw_embeddings = []\n",
    "    wl_embeddings = []\n",
    "    hop_embeddings = []\n",
    "    int_embeddings = []\n",
    "    time_embeddings = []\n",
    "\n",
    "    for snap in range(num_snap):\n",
    "\n",
    "        batch_hop_dict = batch_hop_dicts[snap]\n",
    "\n",
    "        if batch_hop_dict is None:\n",
    "            raw_embeddings.append(None)\n",
    "            wl_embeddings.append(None)\n",
    "            hop_embeddings.append(None)\n",
    "            int_embeddings.append(None)\n",
    "            time_embeddings.append(None)\n",
    "            continue\n",
    "\n",
    "        raw_features_list = []\n",
    "        role_ids_list = []\n",
    "        position_ids_list = []\n",
    "        hop_ids_list = []\n",
    "        time_ids_list = []\n",
    "\n",
    "        for edge_idx in batch_hop_dict:\n",
    "\n",
    "            neighbors_list = batch_hop_dict[edge_idx]\n",
    "            edge = edge_idx.split('_')[1:]\n",
    "            edge[0], edge[1] = int(edge[0]), int(edge[1])\n",
    "\n",
    "            raw_features = []\n",
    "            role_ids = []\n",
    "            position_ids = []\n",
    "            hop_ids = []\n",
    "            time_ids = []\n",
    "\n",
    "            for neighbor, intimacy_rank, hop, time in neighbors_list:\n",
    "                if use_raw_feat:\n",
    "                    raw_features.append(feats[snap-time][neighbor])\n",
    "                else:\n",
    "                    raw_features.append(None)\n",
    "                role_ids.append(wl_dict[neighbor])\n",
    "                hop_ids.append(hop)\n",
    "                position_ids.append(intimacy_rank)\n",
    "                time_ids.append(time)\n",
    "\n",
    "            raw_features_list.append(raw_features)\n",
    "            role_ids_list.append(role_ids)\n",
    "            position_ids_list.append(position_ids)\n",
    "            hop_ids_list.append(hop_ids)\n",
    "            time_ids_list.append(time_ids)\n",
    "\n",
    "        if use_raw_feat:\n",
    "            raw_embedding = torch.FloatTensor(raw_features_list)\n",
    "        else:\n",
    "            raw_embedding = None\n",
    "        wl_embedding = torch.LongTensor(role_ids_list)\n",
    "        hop_embedding = torch.LongTensor(hop_ids_list)\n",
    "        int_embedding = torch.LongTensor(position_ids_list)\n",
    "        time_embedding = torch.LongTensor(time_ids_list)\n",
    "\n",
    "        raw_embeddings.append(raw_embedding)\n",
    "        wl_embeddings.append(wl_embedding)\n",
    "        hop_embeddings.append(hop_embedding)\n",
    "        int_embeddings.append(int_embedding)\n",
    "        time_embeddings.append(time_embedding)\n",
    "\n",
    "    return raw_embeddings, wl_embeddings, hop_embeddings, int_embeddings, time_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2f62e8-1de0-460e-a50e-6b8a400311de",
   "metadata": {},
   "source": [
    "## Compute batch Hops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "450af1b1-566d-48bb-9f96-fda77f5e5dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_batch_hop(node_list, edges_all, num_snap, Ss, k=5, window_size=1):\n",
    "\n",
    "    batch_hop_dicts = [None] * (window_size-1)\n",
    "    s_ranking = [0] + list(range(k+1))\n",
    "\n",
    "    Gs = []\n",
    "    for snap in range(num_snap):\n",
    "        G = nx.Graph()\n",
    "        G.add_nodes_from(node_list)\n",
    "        G.add_edges_from(edges_all[snap])\n",
    "        Gs.append(G)\n",
    "\n",
    "    for snap in range(window_size - 1, num_snap):\n",
    "        batch_hop_dict = {}\n",
    "        # S = Ss[snap]\n",
    "        edges = edges_all[snap]\n",
    "\n",
    "        # G = nx.Graph()\n",
    "        # G.add_nodes_from(node_list)\n",
    "        # G.add_edges_from(edges)\n",
    "\n",
    "        for edge in edges:\n",
    "            edge_idx = str(snap) + '_' + str(edge[0]) + '_' + str(edge[1])\n",
    "            batch_hop_dict[edge_idx] = []\n",
    "            for lookback in range(window_size):\n",
    "                # s = np.array(Ss[snap-lookback][edge[0]] + Ss[snap-lookback][edge[1]].todense()).squeeze()\n",
    "                s = Ss[snap - lookback][edge[0]] + Ss[snap - lookback][edge[1]]\n",
    "                s[edge[0]] = -1000 # don't pick myself\n",
    "                s[edge[1]] = -1000 # don't pick myself\n",
    "                top_k_neighbor_index = s.argsort()[-k:][::-1]\n",
    "\n",
    "                indexs = np.hstack((np.array([edge[0], edge[1]]), top_k_neighbor_index))\n",
    "\n",
    "                for i, neighbor_index in enumerate(indexs):\n",
    "                    try:\n",
    "                        hop1 = nx.shortest_path_length(Gs[snap-lookback], source=edge[0], target=neighbor_index)\n",
    "                    except:\n",
    "                        hop1 = 99\n",
    "                    try:\n",
    "                        hop2 = nx.shortest_path_length(Gs[snap-lookback], source=edge[1], target=neighbor_index)\n",
    "                    except:\n",
    "                        hop2 = 99\n",
    "                    hop = min(hop1, hop2)\n",
    "                    batch_hop_dict[edge_idx].append((neighbor_index, s_ranking[i], hop, lookback))\n",
    "        batch_hop_dicts.append(batch_hop_dict)\n",
    "\n",
    "    return batch_hop_dicts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e0f025-9073-45da-8d03-db73c26ab82e",
   "metadata": {},
   "source": [
    "## Setting connect nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c1cbd9e0-337d-46db-af39-931441735d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WL dict\n",
    "def WL_setting_init(node_list, link_list):\n",
    "    node_color_dict = {}\n",
    "    node_neighbor_dict = {}\n",
    "\n",
    "    for node in node_list:\n",
    "        node_color_dict[node] = 1\n",
    "        node_neighbor_dict[node] = {}\n",
    "\n",
    "    for pair in link_list:\n",
    "        u1, u2 = pair\n",
    "        if u1 not in node_neighbor_dict:\n",
    "            node_neighbor_dict[u1] = {}\n",
    "        if u2 not in node_neighbor_dict:\n",
    "            node_neighbor_dict[u2] = {}\n",
    "        node_neighbor_dict[u1][u2] = 1\n",
    "        node_neighbor_dict[u2][u1] = 1\n",
    "\n",
    "    return node_color_dict, node_neighbor_dict\n",
    "\n",
    "def compute_zero_WL(node_list, link_list):\n",
    "    WL_dict = {}\n",
    "    for i in node_list:\n",
    "        WL_dict[i] = 0\n",
    "    return WL_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09a54b4-e3bd-47ff-b3f6-287cd23af04b",
   "metadata": {},
   "source": [
    "## Dynamic Graph Anomaly Detection Model implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "18fe8222-992c-40e9-9920-a4cba10b86dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DynADModel(BertPreTrainedModel):\n",
    "    learning_record_dict = {}\n",
    "    learn_aucs =  []\n",
    "    learn_aucs_full = []\n",
    "    lr = 0.001\n",
    "    weight_decay = 5e-4\n",
    "    max_epoch = 500\n",
    "    spy_tag = True\n",
    "\n",
    "    load_pretrained_path = ''\n",
    "    save_pretrained_path = ''\n",
    "\n",
    "    def __init__(self, config, args):\n",
    "        super(DynADModel, self).__init__(config, args)\n",
    "        self.args = args\n",
    "        self.config = config\n",
    "        self.transformer = BaseModel(config)\n",
    "        self.cls_y = torch.nn.Linear(config.hidden_size, 1)\n",
    "        self.weight_decay = config.weight_decay\n",
    "        self.init_weights()\n",
    "\n",
    "    def forward(self, init_pos_ids, hop_dis_ids, time_dis_ids, idx=None):\n",
    "\n",
    "        outputs = self.transformer(init_pos_ids, hop_dis_ids, time_dis_ids)\n",
    "\n",
    "        sequence_output = 0\n",
    "        for i in range(self.config.k+1):\n",
    "            sequence_output += outputs[0][:,i,:]\n",
    "        sequence_output /= float(self.config.k+1)\n",
    "\n",
    "        output = self.cls_y(sequence_output)\n",
    "\n",
    "        return output\n",
    "\n",
    "    def batch_cut(self, idx_list):\n",
    "        batch_list = []\n",
    "        for i in range(0, len(idx_list), self.config.batch_size):\n",
    "            batch_list.append(idx_list[i:i + self.config.batch_size])\n",
    "        return batch_list\n",
    "\n",
    "    def evaluate(self, trues, preds):\n",
    "        aucs = {}\n",
    "        for snap in range(len(self.data['snap_test'])):\n",
    "            auc = metrics.roc_auc_score(trues[snap],preds[snap])\n",
    "            aucs[snap] = auc\n",
    "\n",
    "        trues_full = np.hstack(trues)\n",
    "        preds_full = np.hstack(preds)\n",
    "        auc_full = metrics.roc_auc_score(trues_full, preds_full)\n",
    "        \n",
    "        return aucs, auc_full\n",
    "\n",
    "    def generate_embedding(self, edges):\n",
    "        num_snap = len(edges)\n",
    "        # WL_dict = compute_WL(self.data['idx'], np.vstack(edges[:7]))\n",
    "        WL_dict = compute_zero_WL(self.data['idx'],  np.vstack(edges[:7]))\n",
    "        batch_hop_dicts = compute_batch_hop(self.data['idx'], edges, num_snap, self.data['S'], self.config.k, self.config.window_size)\n",
    "        raw_embeddings, wl_embeddings, hop_embeddings, int_embeddings, time_embeddings = \\\n",
    "            dicts_to_embeddings(self.data['X'], batch_hop_dicts, WL_dict, num_snap)\n",
    "        return raw_embeddings, wl_embeddings, hop_embeddings, int_embeddings, time_embeddings\n",
    "\n",
    "    def negative_sampling(self, edges):\n",
    "        negative_edges = []\n",
    "        node_list = self.data['idx']\n",
    "        num_node = node_list.shape[0]\n",
    "        for snap_edge in edges:\n",
    "            num_edge = snap_edge.shape[0]\n",
    "\n",
    "            negative_edge = snap_edge.copy()\n",
    "            fake_idx = np.random.choice(num_node, num_edge)\n",
    "            fake_position = np.random.choice(2, num_edge).tolist()\n",
    "            fake_idx = node_list[fake_idx]\n",
    "            negative_edge[np.arange(num_edge), fake_position] = fake_idx\n",
    "\n",
    "            negative_edges.append(negative_edge)\n",
    "        return negative_edges\n",
    "\n",
    "    def train_model(self, max_epoch):\n",
    "\n",
    "        optimizer = optim.Adam(self.parameters(), lr=self.lr, weight_decay=self.weight_decay)\n",
    "        raw_embeddings, wl_embeddings, hop_embeddings, int_embeddings, time_embeddings = self.generate_embedding(self.data['edges'])\n",
    "        self.data['raw_embeddings'] = None\n",
    "\n",
    "        ns_function = self.negative_sampling\n",
    "\n",
    "        for epoch in range(max_epoch):\n",
    "            t_epoch_begin = time.time()\n",
    "\n",
    "            # -------------------------\n",
    "            negatives = ns_function(self.data['edges'][:max(self.data['snap_train']) + 1])\n",
    "            raw_embeddings_neg, wl_embeddings_neg, hop_embeddings_neg, int_embeddings_neg, \\\n",
    "            time_embeddings_neg = self.generate_embedding(negatives)\n",
    "            self.train()\n",
    "\n",
    "            loss_train = 0\n",
    "            for snap in self.data['snap_train']:\n",
    "\n",
    "                if wl_embeddings[snap] is None:\n",
    "                    continue\n",
    "                int_embedding_pos = int_embeddings[snap]\n",
    "                hop_embedding_pos = hop_embeddings[snap]\n",
    "                time_embedding_pos = time_embeddings[snap]\n",
    "                y_pos = self.data['y'][snap].float()\n",
    "\n",
    "                int_embedding_neg = int_embeddings_neg[snap]\n",
    "                hop_embedding_neg = hop_embeddings_neg[snap]\n",
    "                time_embedding_neg = time_embeddings_neg[snap]\n",
    "                y_neg = torch.ones(int_embedding_neg.size()[0])\n",
    "\n",
    "                int_embedding = torch.vstack((int_embedding_pos, int_embedding_neg))\n",
    "                hop_embedding = torch.vstack((hop_embedding_pos, hop_embedding_neg))\n",
    "                time_embedding = torch.vstack((time_embedding_pos, time_embedding_neg))\n",
    "                y = torch.hstack((y_pos, y_neg))\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                output = self.forward(int_embedding, hop_embedding, time_embedding).squeeze()\n",
    "                loss = F.binary_cross_entropy_with_logits(output, y)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                loss_train += loss.detach().item()\n",
    "\n",
    "            loss_train /= len(self.data['snap_train']) - self.config.window_size + 1\n",
    "            print('Epoch: {}, loss:{:.4f}, Time: {:.4f}s'.format(epoch + 1, loss_train, time.time() - t_epoch_begin))\n",
    "\n",
    "            #\n",
    "            #if ((epoch + 1) % 10self.args.print_feq) == 0:\n",
    "            if ((epoch + 1) % 10) == 0:\n",
    "                self.eval()\n",
    "                preds = []\n",
    "                for snap in self.data['snap_test']:\n",
    "                    int_embedding = int_embeddings[snap]\n",
    "                    hop_embedding = hop_embeddings[snap]\n",
    "                    time_embedding = time_embeddings[snap]\n",
    "\n",
    "                    with torch.no_grad():\n",
    "                        output = self.forward(int_embedding, hop_embedding, time_embedding, None)\n",
    "                        output = torch.sigmoid(output)\n",
    "                    pred = output.squeeze().numpy()\n",
    "                    preds.append(pred)\n",
    "\n",
    "                y_test = self.data['y'][min(self.data['snap_test']):max(self.data['snap_test'])+1]\n",
    "                y_test = [y_snap.numpy() for y_snap in y_test]\n",
    "\n",
    "                aucs, auc_full = self.evaluate(y_test, preds)\n",
    "\n",
    "                self.learn_aucs.append(aucs)\n",
    "                self.learn_aucs_full.append(auc_full)\n",
    "                for i in range(len(self.data['snap_test'])):\n",
    "                    print(\"Snap: %02d | AUC: %.4f\" % (self.data['snap_test'][i], aucs[i]))\n",
    "                print('TOTAL AUC:{:.4f}'.format(auc_full))\n",
    "\n",
    "    def run(self):\n",
    "        self.train_model(self.max_epoch)\n",
    "        #return self.learning_record_dict\n",
    "        return self.learn_aucs, self.learn_aucs_full"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbda9f73-a9f6-4263-8cec-c5cfc7b6725d",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "416541e7-a47a-45b1-bec0-1f8349973518",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyConfig(PretrainedConfig):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        k=5,\n",
    "        max_hop_dis_index = 100,\n",
    "        max_inti_pos_index = 100,\n",
    "        hidden_size=32,\n",
    "        num_hidden_layers=1,\n",
    "        num_attention_heads=1,\n",
    "        intermediate_size=32,\n",
    "        hidden_act=\"gelu\",\n",
    "        hidden_dropout_prob=0.5,\n",
    "        attention_probs_dropout_prob=0.3,\n",
    "        initializer_range=0.02,\n",
    "        layer_norm_eps=1e-12,\n",
    "        is_decoder=False,\n",
    "        batch_size = 256,\n",
    "        window_size = 1,\n",
    "        weight_decay = 5e-4,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super(MyConfig, self).__init__(**kwargs)\n",
    "        self.max_hop_dis_index = max_hop_dis_index\n",
    "        self.max_inti_pos_index = max_inti_pos_index\n",
    "        self.k = k\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_hidden_layers = num_hidden_layers\n",
    "        self.num_attention_heads = num_attention_heads\n",
    "        self.hidden_act = hidden_act\n",
    "        self.intermediate_size = intermediate_size\n",
    "        self.hidden_dropout_prob = hidden_dropout_prob\n",
    "        self.attention_probs_dropout_prob = attention_probs_dropout_prob\n",
    "        self.initializer_range = initializer_range\n",
    "        self.layer_norm_eps = layer_norm_eps\n",
    "        self.is_decoder = is_decoder\n",
    "        self.batch_size = batch_size\n",
    "        self.window_size = window_size\n",
    "        self.weight_decay = weight_decay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d58e7c-3861-4dfc-ab9f-85a008ed2f50",
   "metadata": {},
   "source": [
    "## PreProcess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b88d46d5-7aa0-4dd2-95dc-916de4be2b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessDataset(dataset):\n",
    "    print('Preprocess dataset: ' + dataset)\n",
    "    t0 = time.time()\n",
    "    if dataset in ['digg', 'uci']:\n",
    "        edges = np.loadtxt(\n",
    "            'data/raw/' +\n",
    "            dataset,\n",
    "            dtype=float,\n",
    "            comments='%',\n",
    "            delimiter=' ')\n",
    "        edges = edges[:, 0:2].astype(dtype=int)\n",
    "    elif dataset in ['btc_alpha', 'btc_otc']:\n",
    "        if dataset == 'btc_alpha':\n",
    "            file_name = 'data/raw/' + 'soc-sign-bitcoinalpha.csv'\n",
    "        elif dataset =='btc_otc':\n",
    "            file_name = 'data/raw/' + 'soc-sign-bitcoinotc.csv'\n",
    "        with open(file_name) as f:\n",
    "            lines = f.read().splitlines()\n",
    "        edges = [[float(r) for r in row.split(',')] for row in lines]\n",
    "        edges = np.array(edges)\n",
    "        edges = edges[edges[:, 3].argsort()]\n",
    "        edges = edges[:, 0:2].astype(dtype=int)\n",
    "\n",
    "    for ii in range(len(edges)):\n",
    "        x0 = edges[ii][0]\n",
    "        x1 = edges[ii][1]\n",
    "        if x0 > x1:\n",
    "            edges[ii][0] = x1\n",
    "            edges[ii][1] = x0\n",
    "\n",
    "    edges = edges[np.nonzero([x[0] != x[1] for x in edges])].tolist()\n",
    "    aa, idx = np.unique(edges, return_index=True, axis=0)\n",
    "    edges = np.array(edges)\n",
    "    edges = edges[np.sort(idx)]\n",
    "\n",
    "    vertexs, edges = np.unique(edges, return_inverse=True)\n",
    "    edges = np.reshape(edges, [-1, 2])\n",
    "    print('vertex:', len(vertexs), ' edge: ', len(edges))\n",
    "    np.savetxt(\n",
    "        'data/interim/' +\n",
    "        dataset,\n",
    "        X=edges,\n",
    "        delimiter=' ',\n",
    "        comments='%',\n",
    "        fmt='%d')\n",
    "    print('Preprocess finished! Time: %.2f s' % (time.time() - t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a7a0ab7-d2db-4a1c-9462-fdb04f839c2f",
   "metadata": {},
   "source": [
    "## Generate Anomaly data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1f3e3b1a-473a-4f85-8dd6-3f22857e2bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateDataset(dataset, snap_size, train_per=0.5, anomaly_per=0.01):\n",
    "    print('Generating data with anomaly for Dataset: ', dataset)\n",
    "    if not os.path.exists('data/interim/' + dataset):\n",
    "        preprocessDataset(dataset)\n",
    "    edges = np.loadtxt(\n",
    "        'data/interim/' +\n",
    "        dataset,\n",
    "        dtype=float,\n",
    "        comments='%',\n",
    "        delimiter=' ')\n",
    "    edges = edges[:, 0:2].astype(dtype=int)\n",
    "    vertices = np.unique(edges)\n",
    "    m = len(edges)\n",
    "    n = len(vertices)\n",
    "\n",
    "    t0 = time.time()\n",
    "    synthetic_test, train_mat, train = anomaly_generation(train_per, anomaly_per, edges, n, m, seed=1)\n",
    "\n",
    "    print(\"Anomaly Generation finish! Time: %.2f s\"%(time.time()-t0))\n",
    "    t0 = time.time()\n",
    "\n",
    "    train_mat = (train_mat + train_mat.transpose() + sparse.eye(n)).tolil()\n",
    "    headtail = train_mat.rows\n",
    "    del train_mat\n",
    "\n",
    "    train_size = int(len(train) / snap_size + 0.5)\n",
    "    test_size = int(len(synthetic_test) / snap_size + 0.5)\n",
    "    print(\"Train size:%d  %d  Test size:%d %d\" %\n",
    "          (len(train), train_size, len(synthetic_test), test_size))\n",
    "    rows = []\n",
    "    cols = []\n",
    "    weis = []\n",
    "    labs = []\n",
    "    for ii in range(train_size):\n",
    "        start_loc = ii * snap_size\n",
    "        end_loc = (ii + 1) * snap_size\n",
    "\n",
    "        row = np.array(train[start_loc:end_loc, 0], dtype=np.int32)\n",
    "        col = np.array(train[start_loc:end_loc, 1], dtype=np.int32)\n",
    "        lab = np.zeros_like(row, dtype=np.int32)\n",
    "        wei = np.ones_like(row, dtype=np.int32)\n",
    "\n",
    "        rows.append(row)\n",
    "        cols.append(col)\n",
    "        weis.append(wei)\n",
    "        labs.append(lab)\n",
    "\n",
    "    print(\"Training dataset contruction finish! Time: %.2f s\" % (time.time()-t0))\n",
    "    t0 = time.time()\n",
    "\n",
    "    for i in range(test_size):\n",
    "        start_loc = i * snap_size\n",
    "        end_loc = (i + 1) * snap_size\n",
    "\n",
    "        row = np.array(synthetic_test[start_loc:end_loc, 0], dtype=np.int32)\n",
    "        col = np.array(synthetic_test[start_loc:end_loc, 1], dtype=np.int32)\n",
    "        lab = np.array(synthetic_test[start_loc:end_loc, 2], dtype=np.int32)\n",
    "        wei = np.ones_like(row, dtype=np.int32)\n",
    "\n",
    "        rows.append(row)\n",
    "        cols.append(col)\n",
    "        weis.append(wei)\n",
    "        labs.append(lab)\n",
    "\n",
    "    print(\"Test dataset finish constructing! Time: %.2f s\" % (time.time()-t0))\n",
    "\n",
    "    with open('data/percent/' + dataset + '_' + str(train_per) + '_' + str(anomaly_per) + '.pkl', 'wb') as f:\n",
    "        pickle.dump((rows,cols,labs,weis,headtail,train_size,test_size,n,m),f,pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee23f083-7393-48a7-b04d-ca10d106bbb0",
   "metadata": {},
   "source": [
    "## Create data using Generate Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e6d3674b-8055-4aea-94f2-4909df1a0574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating data with anomaly for Dataset:  uci\n",
      "[#s] generating anomalous dataset...\n",
      " 2024-02-28 17:54:31.124361\n",
      "[#s] initial network edge percent: #.1f##, anomaly percent: #.1f##.\n",
      " 2024-02-28 17:54:31.124378 50.0 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/pytorch/lib/python3.10/site-packages/sklearn/manifold/_spectral_embedding.py:273: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anomaly Generation finish! Time: 3.03 s\n",
      "Train size:6919  7  Test size:6988 7\n",
      "Training dataset contruction finish! Time: 0.00 s\n",
      "Test dataset finish constructing! Time: 0.00 s\n",
      "Generating data with anomaly for Dataset:  uci\n",
      "[#s] generating anomalous dataset...\n",
      " 2024-02-28 17:54:34.162783\n",
      "[#s] initial network edge percent: #.1f##, anomaly percent: #.1f##.\n",
      " 2024-02-28 17:54:34.162794 50.0 5.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/pytorch/lib/python3.10/site-packages/sklearn/manifold/_spectral_embedding.py:273: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anomaly Generation finish! Time: 3.05 s\n",
      "Train size:6919  7  Test size:7264 7\n",
      "Training dataset contruction finish! Time: 0.00 s\n",
      "Test dataset finish constructing! Time: 0.00 s\n",
      "Generating data with anomaly for Dataset:  uci\n",
      "[#s] generating anomalous dataset...\n",
      " 2024-02-28 17:54:37.217751\n",
      "[#s] initial network edge percent: #.1f##, anomaly percent: #.1f##.\n",
      " 2024-02-28 17:54:37.217761 50.0 10.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/pytorch/lib/python3.10/site-packages/sklearn/manifold/_spectral_embedding.py:273: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anomaly Generation finish! Time: 3.00 s\n",
      "Train size:6919  7  Test size:7610 8\n",
      "Training dataset contruction finish! Time: 0.00 s\n",
      "Test dataset finish constructing! Time: 0.00 s\n"
     ]
    }
   ],
   "source": [
    "snap_size_dict = {'uci':1000, 'digg':6000, 'btc_alpha':1000, 'btc_otc':2000}\n",
    "anomaly_pers = [0.01, 0.05, 0.10]\n",
    "#Depending on dataset change 'uci', 'digg', 'btc_alpha', 'btc_otc'\n",
    "#Raw data is avilable in data/raw\n",
    "for anomaly_per in anomaly_pers:\n",
    "        generateDataset( 'uci', snap_size_dict['uci'], train_per=0.5, anomaly_per=anomaly_per)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99cf3222-757e-4835-b37a-5fa97a1ca6d2",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "965b7a61-ff0c-47e7-bc58-677c11e13c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DynamicDatasetLoader():\n",
    "    c = 0.15\n",
    "    k = 5\n",
    "    eps = 0.001\n",
    "    window_size = 2\n",
    "    data = None\n",
    "    batch_size = 256\n",
    "    dataset_name = ''\n",
    "    load_all_tag = False\n",
    "    compute_s = True\n",
    "    anomaly_per = 0.1\n",
    "    train_per = 0.5\n",
    "\n",
    "    def __init__(self, dataset):\n",
    "        self.dataset_name = dataset\n",
    "\n",
    "    def load_hop_wl_batch(self):  #load the \"raw\" WL/Hop/Batch dict\n",
    "        print('Load WL Dictionary')\n",
    "        f = open('./result/WL/' + self.dataset_name, 'rb')\n",
    "        wl_dict = pickle.load(f)\n",
    "        f.close()\n",
    "\n",
    "        print('Load Hop Distance Dictionary')\n",
    "        f = open('./result/Hop/hop_' + self.dataset_name + '_' + str(self.k) + '_' + str(self.window_size), 'rb')\n",
    "        hop_dict = pickle.load(f)\n",
    "        f.close()\n",
    "\n",
    "        print('Load Subgraph Batches')\n",
    "        f = open('./result/Batch/' + self.dataset_name + '_' + str(self.k) + '_' + str(self.window_size), 'rb')\n",
    "        batch_dict = pickle.load(f)\n",
    "        f.close()\n",
    "\n",
    "        return hop_dict, wl_dict, batch_dict\n",
    "\n",
    "    def normalize(self, mx):\n",
    "        \"\"\"Row-normalize sparse matrix\"\"\"\n",
    "        rowsum = np.array(mx.sum(1))\n",
    "        r_inv = np.power(rowsum, -1).flatten()\n",
    "        r_inv[np.isinf(r_inv)] = 0.\n",
    "        r_mat_inv = sp.diags(r_inv)\n",
    "        mx = r_mat_inv.dot(mx)\n",
    "        return mx\n",
    "\n",
    "    def normalize_adj(self, adj):\n",
    "        \"\"\"Symmetrically normalize adjacency matrix. (0226)\"\"\"\n",
    "        adj = sp.coo_matrix(adj)\n",
    "        rowsum = np.array(adj.sum(1))\n",
    "        d_inv_sqrt = np.power(rowsum, -0.5).flatten()\n",
    "        d_inv_sqrt[np.isinf(d_inv_sqrt)] = 0.\n",
    "        d_mat_inv_sqrt = sp.diags(d_inv_sqrt)\n",
    "        return adj.dot(d_mat_inv_sqrt).transpose().dot(d_mat_inv_sqrt).tocoo()\n",
    "\n",
    "    def adj_normalize(self, mx):\n",
    "        \"\"\"Row-normalize sparse matrix\"\"\"\n",
    "        rowsum = np.array(mx.sum(1))\n",
    "        r_inv = np.power(rowsum, -0.5).flatten()\n",
    "        r_inv[np.isinf(r_inv)] = 0.\n",
    "        r_mat_inv = sp.diags(r_inv)\n",
    "        mx = r_mat_inv.dot(mx).dot(r_mat_inv)\n",
    "        return mx\n",
    "\n",
    "    def accuracy(self, output, labels):\n",
    "        preds = output.max(1)[1].type_as(labels)\n",
    "        correct = preds.eq(labels).double()\n",
    "        correct = correct.sum()\n",
    "        return correct / len(labels)\n",
    "\n",
    "    def sparse_mx_to_torch_sparse_tensor(self, sparse_mx):\n",
    "        \"\"\"Convert a scipy sparse matrix to a torch sparse tensor.\"\"\"\n",
    "        sparse_mx = sparse_mx.tocoo().astype(np.float32)\n",
    "        indices = torch.from_numpy(\n",
    "            np.vstack((sparse_mx.row, sparse_mx.col)).astype(np.int64))\n",
    "        values = torch.from_numpy(sparse_mx.data)\n",
    "        shape = torch.Size(sparse_mx.shape)\n",
    "        return torch.sparse.FloatTensor(indices, values, shape)\n",
    "\n",
    "    def encode_onehot(self, labels):\n",
    "        classes = set(labels)\n",
    "        classes_dict = {c: np.identity(len(classes))[i, :] for i, c in\n",
    "                        enumerate(classes)}\n",
    "        labels_onehot = np.array(list(map(classes_dict.get, labels)),\n",
    "                                 dtype=np.int32)\n",
    "        return labels_onehot\n",
    "\n",
    "    def sparse_to_tuple(self, sparse_mx):\n",
    "        \"\"\"Convert sparse matrix to tuple representation. (0226)\"\"\"\n",
    "\n",
    "        def to_tuple(mx):\n",
    "            if not sp.isspmatrix_coo(mx):\n",
    "                mx = mx.tocoo()\n",
    "            coords = np.vstack((mx.row, mx.col)).transpose()\n",
    "            values = mx.data\n",
    "            shape = mx.shape\n",
    "            return coords, values, shape\n",
    "\n",
    "        if isinstance(sparse_mx, list):\n",
    "            for i in range(len(sparse_mx)):\n",
    "                sparse_mx[i] = to_tuple(sparse_mx[i])\n",
    "        else:\n",
    "            sparse_mx = to_tuple(sparse_mx)\n",
    "\n",
    "        return sparse_mx\n",
    "\n",
    "    def preprocess_adj(self, adj):\n",
    "        \"\"\"Preprocessing of adjacency matrix for simple GCN model and conversion to tuple representation. (0226)\"\"\"\n",
    "        adj = adj + adj.T.multiply(adj.T > adj) - adj.multiply(adj.T > adj)\n",
    "        # adj_np = np.array(adj.todense())\n",
    "        adj_normalized = self.normalize_adj(adj + sp.eye(adj.shape[0]))\n",
    "        adj_normalized = self.sparse_mx_to_torch_sparse_tensor(adj_normalized)\n",
    "        return adj_normalized\n",
    "\n",
    "    def get_adjs(self, rows, cols, weights, nb_nodes):\n",
    "\n",
    "        eigen_file_name = 'data/eigen/' + self.dataset_name + '_' + str(self.train_per) + '_' + str(self.anomaly_per) + '.pkl'\n",
    "        if not os.path.exists(eigen_file_name):\n",
    "            generate_eigen = True\n",
    "            print('Generating eigen as: ' + eigen_file_name)\n",
    "        else:\n",
    "            generate_eigen = False\n",
    "            print('Loading eigen from: ' + eigen_file_name)\n",
    "            with open(eigen_file_name, 'rb') as f:\n",
    "                eigen_adjs_sparse = pickle.load(f)\n",
    "            eigen_adjs = []\n",
    "            for eigen_adj_sparse in eigen_adjs_sparse:\n",
    "                eigen_adjs.append(np.array(eigen_adj_sparse.todense()))\n",
    "\n",
    "        adjs = []\n",
    "        if generate_eigen:\n",
    "            eigen_adjs = []\n",
    "            eigen_adjs_sparse = []\n",
    "\n",
    "        for i in range(len(rows)):\n",
    "            adj = sp.csr_matrix((weights[i], (rows[i], cols[i])), shape=(nb_nodes, nb_nodes), dtype=np.float32)\n",
    "            adjs.append(self.preprocess_adj(adj))\n",
    "            if self.compute_s:\n",
    "                if generate_eigen:\n",
    "                    eigen_adj = self.c * inv((sp.eye(adj.shape[0]) - (1 - self.c) * self.adj_normalize(adj)).toarray())\n",
    "                    for p in range(adj.shape[0]):\n",
    "                        eigen_adj[p,p] = 0.\n",
    "                    eigen_adj = self.normalize(eigen_adj)\n",
    "                    eigen_adjs.append(eigen_adj)\n",
    "                    eigen_adjs_sparse.append(sp.csr_matrix(eigen_adj))\n",
    "\n",
    "            else:\n",
    "                eigen_adjs.append(None)\n",
    "\n",
    "        if generate_eigen:\n",
    "            with open(eigen_file_name, 'wb') as f:\n",
    "                pickle.dump(eigen_adjs_sparse, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "        return adjs, eigen_adjs\n",
    "\n",
    "    def load(self):\n",
    "        \"\"\"Load dynamic network dataset\"\"\"\n",
    "\n",
    "        print('Loading {} dataset...'.format(self.dataset_name))\n",
    "        with open('data/percent/' + self.dataset_name + '_' + str(self.train_per) + '_' + str(self.anomaly_per) + '.pkl', 'rb') as f:\n",
    "            rows, cols, labels, weights, headtail, train_size, test_size, nb_nodes, nb_edges = pickle.load(f)\n",
    "\n",
    "        degrees = np.array([len(x) for x in headtail])\n",
    "        num_snap = test_size + train_size\n",
    "\n",
    "        edges = [np.vstack((rows[i], cols[i])).T for i in range(num_snap)]\n",
    "        adjs, eigen_adjs = self.get_adjs(rows, cols, weights, nb_nodes)\n",
    "\n",
    "        labels = [torch.LongTensor(label) for label in labels]\n",
    "\n",
    "        snap_train = list(range(num_snap))[:train_size]\n",
    "        snap_test = list(range(num_snap))[train_size:]\n",
    "\n",
    "        idx = list(range(nb_nodes))\n",
    "        index_id_map = {i:i for i in idx}\n",
    "        idx = np.array(idx)\n",
    "\n",
    "        return {'X': None, 'A': adjs, 'S': eigen_adjs, 'index_id_map': index_id_map, 'edges': edges,\n",
    "                'y': labels, 'idx': idx, 'snap_train': snap_train, 'degrees': degrees,\n",
    "                'snap_test': snap_test, 'num_snap': num_snap}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f54ced-c1bc-47c3-8b8c-a480f22df312",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2e897cc2-77ef-472d-a041-376f209832fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyConfig(PretrainedConfig):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        k=5,\n",
    "        max_hop_dis_index = 100,\n",
    "        max_inti_pos_index = 100,\n",
    "        hidden_size=32,\n",
    "        num_hidden_layers=2,\n",
    "        num_attention_heads=2,\n",
    "        intermediate_size=32,\n",
    "        hidden_act=\"gelu\",\n",
    "        hidden_dropout_prob=0.5,\n",
    "        attention_probs_dropout_prob=0.3,\n",
    "        initializer_range=0.02,\n",
    "        layer_norm_eps=1e-12,\n",
    "        is_decoder=False,\n",
    "        batch_size = 256,\n",
    "        window_size = 2,\n",
    "        weight_decay = 5e-4,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super(MyConfig, self).__init__(**kwargs)\n",
    "        self.max_hop_dis_index = max_hop_dis_index\n",
    "        self.max_inti_pos_index = max_inti_pos_index\n",
    "        self.k = k\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_hidden_layers = num_hidden_layers\n",
    "        self.num_attention_heads = num_attention_heads\n",
    "        self.hidden_act = hidden_act\n",
    "        self.intermediate_size = intermediate_size\n",
    "        self.hidden_dropout_prob = hidden_dropout_prob\n",
    "        self.attention_probs_dropout_prob = attention_probs_dropout_prob\n",
    "        self.initializer_range = initializer_range\n",
    "        self.layer_norm_eps = layer_norm_eps\n",
    "        self.is_decoder = is_decoder\n",
    "        self.batch_size = batch_size\n",
    "        self.window_size = window_size\n",
    "        self.weight_decay = weight_decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "83bef3fc-e82f-4429-9850-d9bb2dcace1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading btc_alpha dataset...\n",
      "Loading eigen from: data/eigen/btc_alpha_0.5_0.1.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6c/715p0r7d0xddsv0vr8gwy7scshw4pr/T/ipykernel_72213/2504294247.py:75: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1699448803473/work/torch/csrc/utils/tensor_new.cpp:607.)\n",
      "  return torch.sparse.FloatTensor(indices, values, shape)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, loss:0.6864, Time: 2.7778s\n",
      "Epoch: 2, loss:0.6525, Time: 2.9385s\n",
      "Epoch: 3, loss:0.5985, Time: 2.8359s\n",
      "Epoch: 4, loss:0.5253, Time: 2.7182s\n",
      "Epoch: 5, loss:0.4461, Time: 2.7619s\n",
      "Epoch: 6, loss:0.3895, Time: 2.6688s\n",
      "Epoch: 7, loss:0.3519, Time: 2.5823s\n",
      "Epoch: 8, loss:0.3191, Time: 2.5925s\n",
      "Epoch: 9, loss:0.2921, Time: 2.6852s\n",
      "Epoch: 10, loss:0.2715, Time: 2.7132s\n",
      "Snap: 07 | AUC: 0.9063\n",
      "Snap: 08 | AUC: 0.9239\n",
      "Snap: 09 | AUC: 0.9512\n",
      "Snap: 10 | AUC: 0.9445\n",
      "Snap: 11 | AUC: 0.9576\n",
      "Snap: 12 | AUC: 0.9349\n",
      "Snap: 13 | AUC: 0.9740\n",
      "Snap: 14 | AUC: 0.9450\n",
      "TOTAL AUC:0.9416\n",
      "Epoch: 11, loss:0.2476, Time: 2.6444s\n",
      "Epoch: 12, loss:0.2362, Time: 2.7412s\n",
      "Epoch: 13, loss:0.2318, Time: 2.6679s\n",
      "Epoch: 14, loss:0.2214, Time: 2.6248s\n",
      "Epoch: 15, loss:0.2191, Time: 2.8050s\n",
      "Epoch: 16, loss:0.2095, Time: 2.7178s\n",
      "Epoch: 17, loss:0.2008, Time: 2.6392s\n",
      "Epoch: 18, loss:0.1899, Time: 2.6800s\n",
      "Epoch: 19, loss:0.1907, Time: 2.7274s\n",
      "Epoch: 20, loss:0.1847, Time: 2.6008s\n",
      "Snap: 07 | AUC: 0.9115\n",
      "Snap: 08 | AUC: 0.9194\n",
      "Snap: 09 | AUC: 0.9335\n",
      "Snap: 10 | AUC: 0.8977\n",
      "Snap: 11 | AUC: 0.9107\n",
      "Snap: 12 | AUC: 0.9401\n",
      "Snap: 13 | AUC: 0.9419\n",
      "Snap: 14 | AUC: 0.9232\n",
      "TOTAL AUC:0.9235\n",
      "Epoch: 21, loss:0.1848, Time: 2.7618s\n",
      "Epoch: 22, loss:0.1873, Time: 2.5548s\n",
      "Epoch: 23, loss:0.1769, Time: 2.5267s\n",
      "Epoch: 24, loss:0.1696, Time: 2.7660s\n",
      "Epoch: 25, loss:0.1644, Time: 2.6997s\n",
      "Epoch: 26, loss:0.1800, Time: 2.6808s\n",
      "Epoch: 27, loss:0.1713, Time: 2.7384s\n",
      "Epoch: 28, loss:0.1743, Time: 2.6970s\n",
      "Epoch: 29, loss:0.1687, Time: 2.7978s\n",
      "Epoch: 30, loss:0.1810, Time: 2.6456s\n",
      "Snap: 07 | AUC: 0.9108\n",
      "Snap: 08 | AUC: 0.9198\n",
      "Snap: 09 | AUC: 0.9316\n",
      "Snap: 10 | AUC: 0.8795\n",
      "Snap: 11 | AUC: 0.8938\n",
      "Snap: 12 | AUC: 0.9386\n",
      "Snap: 13 | AUC: 0.9372\n",
      "Snap: 14 | AUC: 0.9152\n",
      "TOTAL AUC:0.9165\n",
      "Epoch: 31, loss:0.1755, Time: 2.6692s\n",
      "Epoch: 32, loss:0.1910, Time: 2.7766s\n",
      "Epoch: 33, loss:0.1674, Time: 2.7968s\n",
      "Epoch: 34, loss:0.1677, Time: 2.6528s\n",
      "Epoch: 35, loss:0.1612, Time: 2.8329s\n",
      "Epoch: 36, loss:0.1543, Time: 2.6107s\n",
      "Epoch: 37, loss:0.1489, Time: 3.0270s\n",
      "Epoch: 38, loss:0.1574, Time: 2.7163s\n",
      "Epoch: 39, loss:0.1600, Time: 2.6249s\n",
      "Epoch: 40, loss:0.1621, Time: 2.5665s\n",
      "Snap: 07 | AUC: 0.9101\n",
      "Snap: 08 | AUC: 0.9194\n",
      "Snap: 09 | AUC: 0.9094\n",
      "Snap: 10 | AUC: 0.8405\n",
      "Snap: 11 | AUC: 0.8746\n",
      "Snap: 12 | AUC: 0.9101\n",
      "Snap: 13 | AUC: 0.9060\n",
      "Snap: 14 | AUC: 0.8937\n",
      "TOTAL AUC:0.8960\n",
      "Epoch: 41, loss:0.1566, Time: 2.8230s\n",
      "Epoch: 42, loss:0.1517, Time: 2.6203s\n",
      "Epoch: 43, loss:0.1446, Time: 2.6403s\n",
      "Epoch: 44, loss:0.1593, Time: 2.7262s\n",
      "Epoch: 45, loss:0.1564, Time: 2.7399s\n",
      "Epoch: 46, loss:0.1607, Time: 2.5091s\n",
      "Epoch: 47, loss:0.1460, Time: 2.7036s\n",
      "Epoch: 48, loss:0.1608, Time: 2.6428s\n",
      "Epoch: 49, loss:0.1647, Time: 2.6501s\n",
      "Epoch: 50, loss:0.1485, Time: 2.6117s\n",
      "Snap: 07 | AUC: 0.9100\n",
      "Snap: 08 | AUC: 0.9199\n",
      "Snap: 09 | AUC: 0.9198\n",
      "Snap: 10 | AUC: 0.8400\n",
      "Snap: 11 | AUC: 0.8781\n",
      "Snap: 12 | AUC: 0.9086\n",
      "Snap: 13 | AUC: 0.9336\n",
      "Snap: 14 | AUC: 0.8917\n",
      "TOTAL AUC:0.9003\n",
      "Epoch: 51, loss:0.1546, Time: 2.6834s\n",
      "Epoch: 52, loss:0.1522, Time: 2.5527s\n",
      "Epoch: 53, loss:0.1616, Time: 2.6674s\n",
      "Epoch: 54, loss:0.1648, Time: 2.7055s\n",
      "Epoch: 55, loss:0.1411, Time: 2.7400s\n",
      "Epoch: 56, loss:0.1555, Time: 2.6291s\n",
      "Epoch: 57, loss:0.1381, Time: 2.8553s\n",
      "Epoch: 58, loss:0.1616, Time: 2.7443s\n",
      "Epoch: 59, loss:0.1567, Time: 2.7892s\n",
      "Epoch: 60, loss:0.1456, Time: 2.6030s\n",
      "Snap: 07 | AUC: 0.9105\n",
      "Snap: 08 | AUC: 0.9199\n",
      "Snap: 09 | AUC: 0.9039\n",
      "Snap: 10 | AUC: 0.8325\n",
      "Snap: 11 | AUC: 0.8755\n",
      "Snap: 12 | AUC: 0.9053\n",
      "Snap: 13 | AUC: 0.9062\n",
      "Snap: 14 | AUC: 0.8925\n",
      "TOTAL AUC:0.8927\n",
      "Epoch: 61, loss:0.1535, Time: 2.8794s\n",
      "Epoch: 62, loss:0.1548, Time: 2.8330s\n",
      "Epoch: 63, loss:0.1437, Time: 2.6622s\n",
      "Epoch: 64, loss:0.1553, Time: 2.6044s\n",
      "Epoch: 65, loss:0.1530, Time: 2.6015s\n",
      "Epoch: 66, loss:0.1499, Time: 2.9437s\n",
      "Epoch: 67, loss:0.1492, Time: 2.6450s\n",
      "Epoch: 68, loss:0.1458, Time: 2.5846s\n",
      "Epoch: 69, loss:0.1437, Time: 2.7953s\n",
      "Epoch: 70, loss:0.1370, Time: 2.9045s\n",
      "Snap: 07 | AUC: 0.9101\n",
      "Snap: 08 | AUC: 0.9196\n",
      "Snap: 09 | AUC: 0.9209\n",
      "Snap: 10 | AUC: 0.8361\n",
      "Snap: 11 | AUC: 0.8768\n",
      "Snap: 12 | AUC: 0.9051\n",
      "Snap: 13 | AUC: 0.9060\n",
      "Snap: 14 | AUC: 0.8926\n",
      "TOTAL AUC:0.8954\n",
      "Epoch: 71, loss:0.1430, Time: 2.7630s\n",
      "Epoch: 72, loss:0.1429, Time: 2.7459s\n",
      "Epoch: 73, loss:0.1445, Time: 2.7922s\n",
      "Epoch: 74, loss:0.1478, Time: 2.7181s\n",
      "Epoch: 75, loss:0.1407, Time: 2.6592s\n",
      "Epoch: 76, loss:0.1421, Time: 2.7550s\n",
      "Epoch: 77, loss:0.1294, Time: 2.9091s\n",
      "Epoch: 78, loss:0.1463, Time: 2.7353s\n",
      "Epoch: 79, loss:0.1512, Time: 2.6512s\n",
      "Epoch: 80, loss:0.1369, Time: 2.6910s\n",
      "Snap: 07 | AUC: 0.9098\n",
      "Snap: 08 | AUC: 0.9194\n",
      "Snap: 09 | AUC: 0.9147\n",
      "Snap: 10 | AUC: 0.8308\n",
      "Snap: 11 | AUC: 0.8754\n",
      "Snap: 12 | AUC: 0.8974\n",
      "Snap: 13 | AUC: 0.9038\n",
      "Snap: 14 | AUC: 0.8921\n",
      "TOTAL AUC:0.8926\n",
      "Epoch: 81, loss:0.1400, Time: 2.6304s\n",
      "Epoch: 82, loss:0.1341, Time: 2.7240s\n",
      "Epoch: 83, loss:0.1464, Time: 2.6277s\n",
      "Epoch: 84, loss:0.1496, Time: 2.8560s\n",
      "Epoch: 85, loss:0.1482, Time: 2.6519s\n",
      "Epoch: 86, loss:0.1425, Time: 2.7047s\n",
      "Epoch: 87, loss:0.1511, Time: 2.7351s\n",
      "Epoch: 88, loss:0.1404, Time: 2.6815s\n",
      "Epoch: 89, loss:0.1493, Time: 2.7665s\n",
      "Epoch: 90, loss:0.1471, Time: 2.6445s\n",
      "Snap: 07 | AUC: 0.9106\n",
      "Snap: 08 | AUC: 0.9192\n",
      "Snap: 09 | AUC: 0.9014\n",
      "Snap: 10 | AUC: 0.8268\n",
      "Snap: 11 | AUC: 0.8761\n",
      "Snap: 12 | AUC: 0.8932\n",
      "Snap: 13 | AUC: 0.9037\n",
      "Snap: 14 | AUC: 0.8888\n",
      "TOTAL AUC:0.8897\n",
      "Epoch: 91, loss:0.1389, Time: 2.7373s\n",
      "Epoch: 92, loss:0.1441, Time: 2.5699s\n",
      "Epoch: 93, loss:0.1309, Time: 2.9154s\n",
      "Epoch: 94, loss:0.1553, Time: 2.8238s\n",
      "Epoch: 95, loss:0.1402, Time: 2.7113s\n",
      "Epoch: 96, loss:0.1390, Time: 2.7179s\n",
      "Epoch: 97, loss:0.1522, Time: 2.7423s\n",
      "Epoch: 98, loss:0.1430, Time: 2.5869s\n",
      "Epoch: 99, loss:0.1469, Time: 2.6295s\n",
      "Epoch: 100, loss:0.1353, Time: 2.8596s\n",
      "Snap: 07 | AUC: 0.9101\n",
      "Snap: 08 | AUC: 0.9193\n",
      "Snap: 09 | AUC: 0.9195\n",
      "Snap: 10 | AUC: 0.8328\n",
      "Snap: 11 | AUC: 0.8721\n",
      "Snap: 12 | AUC: 0.9006\n",
      "Snap: 13 | AUC: 0.9053\n",
      "Snap: 14 | AUC: 0.8895\n",
      "TOTAL AUC:0.8937\n",
      "Epoch: 101, loss:0.1370, Time: 2.7090s\n",
      "Epoch: 102, loss:0.1359, Time: 2.9184s\n",
      "Epoch: 103, loss:0.1607, Time: 2.6543s\n",
      "Epoch: 104, loss:0.1445, Time: 2.6959s\n",
      "Epoch: 105, loss:0.1392, Time: 2.6216s\n",
      "Epoch: 106, loss:0.1505, Time: 2.5774s\n",
      "Epoch: 107, loss:0.1414, Time: 2.6494s\n",
      "Epoch: 108, loss:0.1387, Time: 2.5326s\n",
      "Epoch: 109, loss:0.1359, Time: 2.6346s\n",
      "Epoch: 110, loss:0.1401, Time: 2.6012s\n",
      "Snap: 07 | AUC: 0.9098\n",
      "Snap: 08 | AUC: 0.9193\n",
      "Snap: 09 | AUC: 0.9012\n",
      "Snap: 10 | AUC: 0.8230\n",
      "Snap: 11 | AUC: 0.8529\n",
      "Snap: 12 | AUC: 0.8827\n",
      "Snap: 13 | AUC: 0.9061\n",
      "Snap: 14 | AUC: 0.8822\n",
      "TOTAL AUC:0.8835\n",
      "Epoch: 111, loss:0.1357, Time: 2.7369s\n",
      "Epoch: 112, loss:0.1526, Time: 2.6747s\n",
      "Epoch: 113, loss:0.1478, Time: 2.7003s\n",
      "Epoch: 114, loss:0.1447, Time: 2.5811s\n",
      "Epoch: 115, loss:0.1372, Time: 2.7468s\n",
      "Epoch: 116, loss:0.1398, Time: 2.6475s\n",
      "Epoch: 117, loss:0.1324, Time: 2.6749s\n",
      "Epoch: 118, loss:0.1374, Time: 2.6199s\n",
      "Epoch: 119, loss:0.1317, Time: 2.5557s\n",
      "Epoch: 120, loss:0.1369, Time: 2.7155s\n",
      "Snap: 07 | AUC: 0.9102\n",
      "Snap: 08 | AUC: 0.9194\n",
      "Snap: 09 | AUC: 0.9060\n",
      "Snap: 10 | AUC: 0.8295\n",
      "Snap: 11 | AUC: 0.8660\n",
      "Snap: 12 | AUC: 0.8971\n",
      "Snap: 13 | AUC: 0.9061\n",
      "Snap: 14 | AUC: 0.8885\n",
      "TOTAL AUC:0.8892\n",
      "Epoch: 121, loss:0.1362, Time: 2.8112s\n",
      "Epoch: 122, loss:0.1406, Time: 2.7411s\n",
      "Epoch: 123, loss:0.1331, Time: 2.6872s\n",
      "Epoch: 124, loss:0.1566, Time: 2.6788s\n",
      "Epoch: 125, loss:0.1455, Time: 2.7258s\n",
      "Epoch: 126, loss:0.1389, Time: 2.8438s\n",
      "Epoch: 127, loss:0.1323, Time: 2.7227s\n",
      "Epoch: 128, loss:0.1375, Time: 2.5313s\n",
      "Epoch: 129, loss:0.1322, Time: 2.8726s\n",
      "Epoch: 130, loss:0.1418, Time: 2.6750s\n",
      "Snap: 07 | AUC: 0.9099\n",
      "Snap: 08 | AUC: 0.9194\n",
      "Snap: 09 | AUC: 0.9201\n",
      "Snap: 10 | AUC: 0.8292\n",
      "Snap: 11 | AUC: 0.8581\n",
      "Snap: 12 | AUC: 0.8815\n",
      "Snap: 13 | AUC: 0.9340\n",
      "Snap: 14 | AUC: 0.8784\n",
      "TOTAL AUC:0.8901\n",
      "Epoch: 131, loss:0.1201, Time: 2.7295s\n",
      "Epoch: 132, loss:0.1401, Time: 2.7295s\n",
      "Epoch: 133, loss:0.1331, Time: 2.7560s\n",
      "Epoch: 134, loss:0.1375, Time: 2.5808s\n",
      "Epoch: 135, loss:0.1472, Time: 2.7131s\n",
      "Epoch: 136, loss:0.1371, Time: 2.6248s\n",
      "Epoch: 137, loss:0.1297, Time: 2.6960s\n",
      "Epoch: 138, loss:0.1345, Time: 2.6914s\n",
      "Epoch: 139, loss:0.1422, Time: 2.8087s\n",
      "Epoch: 140, loss:0.1297, Time: 2.7070s\n",
      "Snap: 07 | AUC: 0.9097\n",
      "Snap: 08 | AUC: 0.9189\n",
      "Snap: 09 | AUC: 0.9129\n",
      "Snap: 10 | AUC: 0.8245\n",
      "Snap: 11 | AUC: 0.8640\n",
      "Snap: 12 | AUC: 0.8863\n",
      "Snap: 13 | AUC: 0.9056\n",
      "Snap: 14 | AUC: 0.8841\n",
      "TOTAL AUC:0.8874\n",
      "Epoch: 141, loss:0.1331, Time: 2.7352s\n",
      "Epoch: 142, loss:0.1251, Time: 2.8177s\n",
      "Epoch: 143, loss:0.1453, Time: 2.7423s\n",
      "Epoch: 144, loss:0.1311, Time: 2.6041s\n",
      "Epoch: 145, loss:0.1258, Time: 2.8354s\n",
      "Epoch: 146, loss:0.1397, Time: 2.6768s\n",
      "Epoch: 147, loss:0.1319, Time: 2.6126s\n",
      "Epoch: 148, loss:0.1397, Time: 2.6130s\n",
      "Epoch: 149, loss:0.1495, Time: 2.7019s\n",
      "Epoch: 150, loss:0.1419, Time: 2.7462s\n",
      "Snap: 07 | AUC: 0.9107\n",
      "Snap: 08 | AUC: 0.9192\n",
      "Snap: 09 | AUC: 0.9042\n",
      "Snap: 10 | AUC: 0.8277\n",
      "Snap: 11 | AUC: 0.8598\n",
      "Snap: 12 | AUC: 0.8878\n",
      "Snap: 13 | AUC: 0.9061\n",
      "Snap: 14 | AUC: 0.8853\n",
      "TOTAL AUC:0.8865\n",
      "Epoch: 151, loss:0.1432, Time: 2.7027s\n",
      "Epoch: 152, loss:0.1434, Time: 2.6514s\n",
      "Epoch: 153, loss:0.1282, Time: 2.9319s\n",
      "Epoch: 154, loss:0.1444, Time: 2.5756s\n",
      "Epoch: 155, loss:0.1312, Time: 2.6461s\n",
      "Epoch: 156, loss:0.1333, Time: 2.8412s\n",
      "Epoch: 157, loss:0.1348, Time: 2.8105s\n",
      "Epoch: 158, loss:0.1444, Time: 2.6808s\n",
      "Epoch: 159, loss:0.1370, Time: 3.0319s\n",
      "Epoch: 160, loss:0.1430, Time: 2.6466s\n",
      "Snap: 07 | AUC: 0.9091\n",
      "Snap: 08 | AUC: 0.9180\n",
      "Snap: 09 | AUC: 0.9012\n",
      "Snap: 10 | AUC: 0.7697\n",
      "Snap: 11 | AUC: 0.8233\n",
      "Snap: 12 | AUC: 0.8522\n",
      "Snap: 13 | AUC: 0.9058\n",
      "Snap: 14 | AUC: 0.8562\n",
      "TOTAL AUC:0.8646\n",
      "Epoch: 161, loss:0.1329, Time: 2.6403s\n",
      "Epoch: 162, loss:0.1431, Time: 2.6624s\n",
      "Epoch: 163, loss:0.1401, Time: 2.6422s\n",
      "Epoch: 164, loss:0.1313, Time: 2.8258s\n",
      "Epoch: 165, loss:0.1226, Time: 2.6524s\n",
      "Epoch: 166, loss:0.1367, Time: 2.7147s\n",
      "Epoch: 167, loss:0.1364, Time: 2.5588s\n",
      "Epoch: 168, loss:0.1292, Time: 2.7964s\n",
      "Epoch: 169, loss:0.1464, Time: 2.9588s\n",
      "Epoch: 170, loss:0.1376, Time: 2.8903s\n",
      "Snap: 07 | AUC: 0.9090\n",
      "Snap: 08 | AUC: 0.9183\n",
      "Snap: 09 | AUC: 0.9011\n",
      "Snap: 10 | AUC: 0.8095\n",
      "Snap: 11 | AUC: 0.8435\n",
      "Snap: 12 | AUC: 0.8645\n",
      "Snap: 13 | AUC: 0.9060\n",
      "Snap: 14 | AUC: 0.8739\n",
      "TOTAL AUC:0.8770\n",
      "Epoch: 171, loss:0.1390, Time: 2.5949s\n",
      "Epoch: 172, loss:0.1349, Time: 2.7629s\n",
      "Epoch: 173, loss:0.1302, Time: 2.7915s\n",
      "Epoch: 174, loss:0.1387, Time: 2.6532s\n",
      "Epoch: 175, loss:0.1445, Time: 2.7022s\n",
      "Epoch: 176, loss:0.1516, Time: 2.4745s\n",
      "Epoch: 177, loss:0.1336, Time: 2.7260s\n",
      "Epoch: 178, loss:0.1458, Time: 2.5867s\n",
      "Epoch: 179, loss:0.1435, Time: 2.5516s\n",
      "Epoch: 180, loss:0.1290, Time: 2.8273s\n",
      "Snap: 07 | AUC: 0.9098\n",
      "Snap: 08 | AUC: 0.9190\n",
      "Snap: 09 | AUC: 0.9162\n",
      "Snap: 10 | AUC: 0.8267\n",
      "Snap: 11 | AUC: 0.8641\n",
      "Snap: 12 | AUC: 0.8917\n",
      "Snap: 13 | AUC: 0.9062\n",
      "Snap: 14 | AUC: 0.8864\n",
      "TOTAL AUC:0.8894\n",
      "Epoch: 181, loss:0.1274, Time: 2.7203s\n",
      "Epoch: 182, loss:0.1372, Time: 2.8119s\n",
      "Epoch: 183, loss:0.1350, Time: 2.6583s\n",
      "Epoch: 184, loss:0.1515, Time: 2.6652s\n",
      "Epoch: 185, loss:0.1297, Time: 2.8902s\n",
      "Epoch: 186, loss:0.1320, Time: 2.9410s\n",
      "Epoch: 187, loss:0.1324, Time: 2.7827s\n",
      "Epoch: 188, loss:0.1369, Time: 2.7387s\n",
      "Epoch: 189, loss:0.1398, Time: 2.7103s\n",
      "Epoch: 190, loss:0.1432, Time: 2.7517s\n",
      "Snap: 07 | AUC: 0.9097\n",
      "Snap: 08 | AUC: 0.9187\n",
      "Snap: 09 | AUC: 0.9032\n",
      "Snap: 10 | AUC: 0.8170\n",
      "Snap: 11 | AUC: 0.8497\n",
      "Snap: 12 | AUC: 0.8672\n",
      "Snap: 13 | AUC: 0.9059\n",
      "Snap: 14 | AUC: 0.8790\n",
      "TOTAL AUC:0.8801\n",
      "Epoch: 191, loss:0.1294, Time: 2.7864s\n",
      "Epoch: 192, loss:0.1318, Time: 2.6748s\n",
      "Epoch: 193, loss:0.1404, Time: 2.5504s\n",
      "Epoch: 194, loss:0.1358, Time: 2.7121s\n",
      "Epoch: 195, loss:0.1439, Time: 2.6282s\n",
      "Epoch: 196, loss:0.1425, Time: 2.7234s\n",
      "Epoch: 197, loss:0.1425, Time: 2.5610s\n",
      "Epoch: 198, loss:0.1268, Time: 2.8326s\n",
      "Epoch: 199, loss:0.1334, Time: 2.6458s\n",
      "Epoch: 200, loss:0.1373, Time: 2.5753s\n",
      "Snap: 07 | AUC: 0.9101\n",
      "Snap: 08 | AUC: 0.9189\n",
      "Snap: 09 | AUC: 0.9153\n",
      "Snap: 10 | AUC: 0.8228\n",
      "Snap: 11 | AUC: 0.8664\n",
      "Snap: 12 | AUC: 0.8886\n",
      "Snap: 13 | AUC: 0.9036\n",
      "Snap: 14 | AUC: 0.8848\n",
      "TOTAL AUC:0.8889\n"
     ]
    }
   ],
   "source": [
    "#import argparse\n",
    "import networkx as nx\n",
    "data_obj = DynamicDatasetLoader('btc_alpha')\n",
    "data_obj.dataset_name = 'btc_alpha'\n",
    "my_config = MyConfig()\n",
    "TransformerLayerNorm = torch.nn.LayerNorm\n",
    "np.random.seed(10)\n",
    "torch.manual_seed(10)\n",
    "method_obj = DynADModel(my_config, '')\n",
    "method_obj.spy_tag = True\n",
    "method_obj.max_epoch = 200\n",
    "method_obj.lr = 0.001\n",
    "loaded_data = data_obj.load()\n",
    "method_obj.data = loaded_data\n",
    "la,laf=method_obj.run()\n",
    "#print(la)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0928e82-65f2-4105-8930-6240a1091105",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
